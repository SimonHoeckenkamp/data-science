{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Neural Networks\n",
    "## 1. Feed Forward Neural Network\n",
    "\n",
    "Implementing simple Feed Forward neural network.\n",
    "\n",
    "* Input layer x (consisting of two features), hidden layer (consisting of four nodes) and output layer (consisting of two nodes)\n",
    "* Usage of ReLU activation function on each layer $f(z) = max\\{z, 0\\}$, $f(u) = max\\{u, 0\\}$\n",
    "* Usage on softmax function for calculating probabilities on each element of output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![schema of Feed Forward neuronal network](https://courses.edx.org/assets/courseware/v1/a9b004b0d6dbb3aea99347118218126d/asset-v1:MITx+6.86x+1T2021+type@asset+block/images_hw4_p1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU function (return max{x, 0}, works for scalars and vectors)\n",
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "# softmax function (input and output is array of shape (n,))\n",
    "def softmax(X):\n",
    "    softmax_X = np.exp(X)\n",
    "    return softmax_X / np.sum(softmax_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 0,  1, -1],\n",
       "       [-1,  0, -1],\n",
       "       [ 0, -1, -1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define matrices for weighing factors\n",
    "W = np.array([[1,0,-1],[0,1,-1],[-1,0,-1],[0,-1,-1]])\n",
    "V = np.array([[1,1,1,1,0],[-1,-1,-1,-1,2]])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define input data\n",
    "x = np.array([3,14])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 13.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.empty(4)\n",
    "for i in range(W.shape[0]):\n",
    "    z[i] = np.dot(W[i,0:2], x) + W[i,2]\n",
    "\n",
    "z = relu(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.matmul(V[:,0:4], z)\n",
    "u = u + V[:, 4]\n",
    "u = relu(u)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99999694e-01, 3.05902227e-07])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the softmax function of the output-layer\n",
    "o = softmax(u)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_1:  0.5\n",
      "o_1:  0.11920292202211755\n",
      "o_1:  0.9525741268224333\n"
     ]
    }
   ],
   "source": [
    "# task: 'Output of Neural Network'\n",
    "new_u = np.array([[1,1],[0,2],[3,-1]])\n",
    "for i in range(len(new_u)):\n",
    "    new_u = relu(new_u)\n",
    "    new_o = softmax(new_u[i])\n",
    "    print(\"o_1: \", new_o[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM (long short term memory)\n",
    "\n",
    "The following code returns parameters regarding to consecutive digits of {0, 1} as input vector\n",
    " * 1: odd no. of ones\n",
    " * -1: even no. of ones \n",
    " * 0: zero in corresponding position of input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://courses.edx.org/assets/courseware/v1/8e7c0fe7c60323338b556ae490d116cf/asset-v1:MITx+6.86x+1T2021+type@asset+block/images_hw4_p2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of helper functions for the LSTM-Problem\n",
    "\n",
    "# sigmoid function, returns values between [0,1] \n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "# definition of simplified sigmoid function with respect to the task\n",
    "def sigmoid_simplified(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range (X.shape[1]):\n",
    "            if X[i,j] >= 1:\n",
    "                X[i,j] = 1\n",
    "            elif X[i,j] <= -1:\n",
    "                X[i,j] = 0\n",
    "            else:\n",
    "                X[i,j] = sigmoid(X[i,j])\n",
    "    return X\n",
    "\n",
    "def sigmoid_simplified_scalar(X):\n",
    "    if X >= 1:\n",
    "        return 1\n",
    "    elif X <= -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return sigmoid(X)\n",
    "                \n",
    "# analogue simplified tanh function\n",
    "def tanh_simplified(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range (X.shape[1]):\n",
    "            if X[i,j] >= 1:\n",
    "                X[i,j] = 1\n",
    "            elif X[i,j] <= -1:\n",
    "                X[i,j] = -1\n",
    "            else:\n",
    "                X[i,j] = np.tanh(X[i,j])\n",
    "    return X\n",
    "\n",
    "def tanh_simplified_scalar(X):\n",
    "    if X >= 1:\n",
    "        return 1\n",
    "    elif X <= -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return np.tanh(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of parameters for the NN, \n",
    "# for the sake of simplicity consisting of scalars\n",
    "W_f_h = 0\n",
    "W_f_x = 0\n",
    "W_i_h = 0\n",
    "W_i_x = 100\n",
    "W_o_h = 0\n",
    "W_o_x = 100\n",
    "W_c_h = -100\n",
    "W_c_x = 50\n",
    "b_f = -100\n",
    "b_i = 100\n",
    "b_o = 0\n",
    "b_c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid simplified:  [[0.         0.        ]\n",
      " [0.2890505  0.31002552]\n",
      " [0.33181223 0.35434369]\n",
      " [0.37754067 0.40131234]\n",
      " [0.42555748 0.450166  ]\n",
      " [0.47502081 0.5       ]\n",
      " [0.52497919 0.549834  ]\n",
      " [0.57444252 0.59868766]\n",
      " [0.62245933 0.64565631]\n",
      " [0.66818777 0.68997448]\n",
      " [0.7109495  1.        ]]\n",
      "tanh simplified:  [[0.         0.        ]\n",
      " [0.28126066 0.30046031]\n",
      " [0.3201482  0.34022211]\n",
      " [0.36056978 0.38107129]\n",
      " [0.40160196 0.42203545]\n",
      " [0.4422471  0.46211716]\n",
      " [0.48153381 0.50039579]\n",
      " [0.51861441 0.53611508]\n",
      " [0.55283804 0.56873856]\n",
      " [0.58378654 0.59796561]\n",
      " [0.6112719  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# test of functions\n",
    "test = np.arange(-1.1,1.1, 0.1).reshape((11,2))\n",
    "print(\"sigmoid simplified: \", sigmoid_simplified(test))\n",
    "print(\"tanh simplified: \", tanh_simplified(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  0.,  1., -1.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the LSTM NN on the given parameters and initial conditions\n",
    "# TODO: Change elementwise multiplication and sigmoid/ tanh fanction for \n",
    "#       calculatione with matrices and vectors\n",
    "\n",
    "# input data\n",
    "x_sequence_1 = np.array([0,0,1,1,1,0])\n",
    "x_sequence_2 = np.array([1,1,0,1,1])\n",
    "x_sequence = x_sequence_2 \n",
    "\n",
    "# initialization\n",
    "f_t = 0\n",
    "i_t = 0\n",
    "o_t = 0\n",
    "c_t = 0 # initialization with c_{t-1} = 0\n",
    "h_t = 0 # initialization with h_{t-1} = 0\n",
    "h_t_list = np.empty(len(x_sequence))\n",
    "for i in range(len(x_sequence)):\n",
    "    x_t = x_sequence[i]\n",
    "    f_t = sigmoid_simplified_scalar(W_f_h * h_t + W_f_x * x_t + b_f)\n",
    "    i_t = sigmoid_simplified_scalar(W_i_h * h_t + W_i_x * x_t + b_i)\n",
    "    o_t = sigmoid_simplified_scalar(W_o_h * h_t + W_o_x * x_t + b_o)\n",
    "    c_t = f_t * c_t + i_t * tanh_simplified_scalar(W_c_h * h_t + W_c_x * x_t + b_c)\n",
    "    h_t = o_t * tanh_simplified_scalar(c_t)\n",
    "    \n",
    "    # round h_t to integer value {-1, 0, 1} in every time step\n",
    "    if h_t <= 0.5 and h_t >= -0.5:\n",
    "        h_t = 0\n",
    "    \n",
    "    h_t_list[i] = h_t\n",
    "h_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
